import streamlit as st
import pandas as pd
import numpy as np
import joblib
import os
import matplotlib.pyplot as plt
import shap

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="CKMç»¼åˆå¾æ—©æœŸï¼ˆ1-2æœŸï¼‰é£é™©é¢„æµ‹å·¥å…·",
    page_icon="ğŸ¥",
    layout="wide"
)

# æ ‡é¢˜å’Œç®€ä»‹
st.title("ğŸ¥ CKMç»¼åˆå¾æ—©æœŸï¼ˆ1-2æœŸï¼‰é£é™©é¢„æµ‹å·¥å…·")
st.markdown("""
æœ¬å·¥å…·åŸºäºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œé€šè¿‡æ‚£è€…çš„ä¸´åºŠç‰¹å¾é¢„æµ‹CKMç»¼åˆå¾æ—©æœŸï¼ˆ1-2æœŸï¼‰çš„é£é™©æ¦‚ç‡ã€‚
è¯·è¾“å…¥ä»¥ä¸‹ 7 ä¸ªç‰¹å¾å€¼è¿›è¡Œé¢„æµ‹ã€‚
""")

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))

# ä¾§è¾¹æ ï¼šæ¨¡å‹é€‰æ‹©
st.sidebar.header("âš™ï¸ è®¾ç½®")
# ä¿®æ”¹ä¸ºç›¸å¯¹è·¯å¾„
model_dir = os.path.join(current_dir, "models")
data_path = os.path.join(current_dir, "data", "ckm0.96666666.xlsx")
plot_dir = os.path.join(current_dir, "plots")
roc_dir = os.path.join(current_dir, "plots", "ROC_Curves")

# è·å–å¯ç”¨æ¨¡å‹
try:
    if os.path.exists(model_dir):
        model_files = [f for f in os.listdir(model_dir) if f.endswith('_model.pkl')]
        model_names = [f.replace('_model.pkl', '') for f in model_files]
        
        # é»˜è®¤é€‰æ‹©æ€§èƒ½è¾ƒå¥½çš„æ¨¡å‹ï¼ˆå¦‚CatBoostæˆ–XGBoostï¼Œå¦‚æœå­˜åœ¨ï¼‰ï¼Œå¦åˆ™é»˜è®¤ç¬¬ä¸€ä¸ª
        default_index = 0
        preferred_models = ['CatBoost', 'XGBoost', 'LightGBM', 'RandomForest']
        for pref in preferred_models:
            if pref in model_names:
                default_index = model_names.index(pref)
                break
                
        selected_model_name = st.sidebar.selectbox("é€‰æ‹©é¢„æµ‹æ¨¡å‹", model_names, index=default_index)
    else:
        st.error(f"æ¨¡å‹ç›®å½•ä¸å­˜åœ¨: {model_dir}")
        st.stop()
except Exception as e:
    st.error(f"æ— æ³•è¯»å–æ¨¡å‹ç›®å½•: {e}")
    st.stop()

# åŠ è½½æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
@st.cache_resource
def load_resources(model_name):
    model_path = os.path.join(model_dir, f"{model_name}_model.pkl")
    scaler_path = os.path.join(model_dir, "scaler.pkl")
    
    try:
        model = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        return model, scaler
    except Exception as e:
        st.error(f"åŠ è½½èµ„æºå¤±è´¥: {e}")
        return None, None

model, scaler = load_resources(selected_model_name)

# åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆç”¨äºSHAPèƒŒæ™¯ï¼‰
@st.cache_resource
def load_data():
    try:
        df = pd.read_excel(data_path)
        # å‡è®¾å‰7åˆ—æ˜¯ç‰¹å¾ï¼Œæœ€åä¸€åˆ—æ˜¯æ ‡ç­¾ï¼Œè¿™é‡Œæˆ‘ä»¬éœ€è¦æ ¹æ®ç‰¹å¾åæå–
        feature_names = ['AGE', 'BMI', 'FBG', 'HBA1C', 'HDL', 'TG', 'UA']
        X = df[feature_names]
        return X
    except Exception as e:
        return None

X_train = load_data()

if model is None or scaler is None:
    st.error("æ¨¡å‹æˆ–æ ‡å‡†åŒ–å™¨åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„ã€‚")
    st.stop()

st.sidebar.success(f"å·²åŠ è½½æ¨¡å‹: {selected_model_name}")

# è¾“å…¥è¡¨å•
st.subheader("ğŸ“ æ‚£è€…ç‰¹å¾è¾“å…¥")

col1, col2, col3 = st.columns(3)

with col1:
    age = st.number_input("å¹´é¾„ (AGE) [å²]", min_value=18.0, max_value=120.0, value=60.0, step=1.0, help="æ‚£è€…çš„å¹´é¾„ï¼Œå•ä½ï¼šå²")
    bmi = st.number_input("ä½“é‡æŒ‡æ•° (BMI) [kg/mÂ²]", min_value=10.0, max_value=60.0, value=24.0, step=0.1, help="Body Mass Indexï¼Œå•ä½ï¼škg mâ»Â²")
    fbg = st.number_input("ç©ºè…¹è¡€ç³– (FBG) [mg/dL]", min_value=1.0, max_value=500.0, value=100.0, step=1.0, help="Fasting Blood Glucoseï¼Œå•ä½ï¼šmg/dL")

with col2:
    hba1c = st.number_input("ç³–åŒ–è¡€çº¢è›‹ç™½ (HbA1c) [%]", min_value=3.0, max_value=20.0, value=6.0, step=0.1, help="Hemoglobin A1cï¼Œå•ä½ï¼š%")
    hdl = st.number_input("é«˜å¯†åº¦è„‚è›‹ç™½ (HDL) [mg/dL]", min_value=1.0, max_value=200.0, value=50.0, step=1.0, help="High-Density Lipoproteinï¼Œå•ä½ï¼šmg/dL")
    tg = st.number_input("ç”˜æ²¹ä¸‰é…¯ (TG) [mg/dL]", min_value=1.0, max_value=1000.0, value=150.0, step=1.0, help="Triglyceridesï¼Œå•ä½ï¼šmg/dL")

with col3:
    ua = st.number_input("å°¿é…¸ (UA) [mg/dL]", min_value=1.0, max_value=20.0, value=5.0, step=0.1, help="Uric Acidï¼Œå•ä½ï¼šmg/dL")

# é¢„æµ‹é€»è¾‘
if st.button("ğŸš€ å¼€å§‹é¢„æµ‹", type="primary"):
    # æ„å»ºè¾“å…¥æ•°æ®
    input_data = pd.DataFrame({
        'AGE': [age],
        'BMI': [bmi],
        'FBG': [fbg],
        'HBA1C': [hba1c],
        'HDL': [hdl],
        'TG': [tg],
        'UA': [ua]
    })
    
    # æ ‡å‡†åŒ–
    try:
        input_scaled = scaler.transform(input_data)
        
        # é¢„æµ‹
        if hasattr(model, "predict_proba"):
            proba = model.predict_proba(input_scaled)[0][1] # è·å–æ­£ç±»æ¦‚ç‡
        else:
            # å¯¹äºä¸æ”¯æŒæ¦‚ç‡çš„æ¨¡å‹ï¼ˆå¦‚æŸäº›SVMé…ç½®ï¼‰ï¼Œä½¿ç”¨predict
            pred = model.predict(input_scaled)[0]
            proba = 1.0 if pred == 1 else 0.0
            st.warning("è¯¥æ¨¡å‹ä¸æ”¯æŒæ¦‚ç‡è¾“å‡ºï¼Œä»…æ˜¾ç¤ºç±»åˆ«é¢„æµ‹ç»“æœã€‚")
            
        # æ˜¾ç¤ºç»“æœ
        st.divider()
        st.subheader("ğŸ“Š é¢„æµ‹ç»“æœ")
        
        c1, c2 = st.columns([1, 2])
        
        with c1:
            risk_percent = proba * 100
            if proba > 0.5:
                st.error(f"**é«˜é£é™©** (High Risk)")
                st.metric("é£é™©æ¦‚ç‡", f"{risk_percent:.2f}%", delta="Risk")
            else:
                st.success(f"**ä½é£é™©** (Low Risk)")
                st.metric("é£é™©æ¦‚ç‡", f"{risk_percent:.2f}%", delta="-Safe", delta_color="normal")
        
        with c2:
            st.write("é£é™©æ¦‚ç‡å¯è§†åŒ–:")
            st.progress(proba)
            
            if proba > 0.7:
                st.write("âš ï¸ **å»ºè®®**: æ‚£è€…CKMç»¼åˆå¾æ—©æœŸï¼ˆ1-2æœŸï¼‰é£é™©**å¾ˆé«˜**ï¼Œå»ºè®®å¯†åˆ‡éšè®¿å¹¶é‡‡å–ç§¯æå¹²é¢„æªæ–½ã€‚")
            elif proba > 0.5:
                st.write("âš ï¸ **å»ºè®®**: æ‚£è€…CKMç»¼åˆå¾æ—©æœŸï¼ˆ1-2æœŸï¼‰é£é™©**è¾ƒé«˜**ï¼Œå»ºè®®å…³æ³¨ç›¸å…³æŒ‡æ ‡å¹¶è€ƒè™‘å¹²é¢„ã€‚")
            elif proba > 0.3:
                st.write("â„¹ï¸ **å»ºè®®**: æ‚£è€…å¤„äº**ä¸­ç­‰é£é™©**ï¼Œå»ºè®®å®šæœŸæ£€æŸ¥ï¼Œä¿æŒè‰¯å¥½ç”Ÿæ´»ä¹ æƒ¯ã€‚")
            else:
                st.write("âœ… **å»ºè®®**: æ‚£è€…ç›®å‰é£é™©**è¾ƒä½**ï¼Œè¯·ç»§ç»­ä¿æŒå¥åº·ç”Ÿæ´»æ–¹å¼ã€‚")
            
            with st.expander("æŸ¥çœ‹è¾“å…¥ç‰¹å¾æ‘˜è¦"):
                display_data = input_data.copy()
                display_data.columns = [
                    'AGE [å²]', 'BMI [kg/mÂ²]', 'FBG [mg/dL]', 
                    'HBA1C [%]', 'HDL [mg/dL]', 'TG [mg/dL]', 'UA [mg/dL]'
                ]
                st.dataframe(display_data)

        st.divider()
        
        # é€‰é¡¹å¡å¸ƒå±€
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ˆ ç‰¹å¾è´¡çŒ®åˆ†æ (SHAP)", "ğŸ“Š é£é™©å› å­é‡è¦æ€§", "ğŸ“‰ æ¨¡å‹æ€§èƒ½ (ROC/Recall)", "ğŸ“‹ è®­ç»ƒæ•°æ®æ‘˜è¦"])
        
        with tab1:
            st.subheader("å•æ ·æœ¬ SHAP è´¡çŒ®åº¦åˆ†æ")
            st.markdown("è¯¥å›¾å±•ç¤ºäº†å„ç‰¹å¾å¯¹**æœ¬æ¬¡é¢„æµ‹ç»“æœ**çš„è´¡çŒ®ç¨‹åº¦ã€‚çº¢è‰²è¡¨ç¤ºå¢åŠ é£é™©ï¼Œè“è‰²è¡¨ç¤ºé™ä½é£é™©ã€‚")
            
            if X_train is not None:
                try:
                    with st.spinner('æ­£åœ¨è®¡ç®— SHAP å€¼ï¼Œè¯·ç¨å€™...'):
                        # å‡†å¤‡èƒŒæ™¯æ•°æ® (å–æ ·ä»¥åŠ å¿«é€Ÿåº¦)
                        background = shap.maskers.Independent(X_train, max_samples=100)
                        
                        # åˆ›å»ºè§£é‡Šå™¨
                        # æ³¨æ„ï¼šä¸åŒæ¨¡å‹éœ€è¦ä¸åŒçš„è§£é‡Šå™¨ï¼Œè¿™é‡Œå°è¯•é€šç”¨æ–¹æ³•
                        explainer = None
                        
                        # å°è¯•ä½¿ç”¨ TreeExplainer (é’ˆå¯¹æ ‘æ¨¡å‹)
                        tree_models = ['XGBoost', 'CatBoost', 'LightGBM', 'RandomForest', 'ExtraTrees', 'DecisionTree', 'GradientBoosting']
                        
                        if selected_model_name in tree_models:
                            try:
                                explainer = shap.TreeExplainer(model)
                            except:
                                # å¦‚æœå¤±è´¥ï¼ˆä¾‹å¦‚sklearnç‰ˆæœ¬å…¼å®¹æ€§ï¼‰ï¼Œå›é€€åˆ°KernelExplainer
                                pass
                        
                        # å¦‚æœä¸æ˜¯æ ‘æ¨¡å‹æˆ–TreeExplainerå¤±è´¥ï¼Œä½¿ç”¨KernelExplainer (é€šç”¨ä½†æ…¢)
                        if explainer is None:
                             # ä½¿ç”¨é¢„æµ‹å‡½æ•°åŒ…è£…å™¨ï¼Œç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
                             f = lambda x: model.predict_proba(x)[:, 1]
                             # ä½¿ç”¨kmeansèšç±»å‡å°‘èƒŒæ™¯æ ·æœ¬æ•°ï¼ŒåŠ å¿«è®¡ç®—
                             X_train_summary = shap.kmeans(X_train, 10)
                             explainer = shap.KernelExplainer(f, X_train_summary)
                        
                        # è®¡ç®—å½“å‰æ ·æœ¬çš„SHAPå€¼
                        # æ³¨æ„ï¼šè¾“å…¥éœ€è¦æ˜¯DataFrameä¸”åˆ—ååŒ¹é…
                        shap_values = explainer(input_data)

                        # æ›´æ–°ç‰¹å¾åç§°ä»¥åŒ…å«å•ä½ï¼ˆç”¨äºç»˜å›¾ï¼‰
                        shap_values.feature_names = [
                            'AGE [å²]', 'BMI [kg/mÂ²]', 'FBG [mg/dL]', 
                            'HBA1C [%]', 'HDL [mg/dL]', 'TG [mg/dL]', 'UA [mg/dL]'
                        ]
                        
                        # ç»˜åˆ¶ç€‘å¸ƒå›¾
                        fig, ax = plt.subplots(figsize=(10, 6))
                        # shap.plots.waterfall(shap_values[0], show=False) # æ—§ç‰ˆå¯èƒ½ä¸æ”¯æŒ
                        # ä½¿ç”¨ matplotlib ç»˜åˆ¶
                        shap.plots.waterfall(shap_values[0], show=False)
                        st.pyplot(fig)
                        plt.close()
                        
                except Exception as e:
                    st.warning(f"æ— æ³•ç”Ÿæˆå®æ—¶ SHAP å›¾ ({str(e)})ã€‚è¯·å‚è€ƒä¸‹æ–¹çš„å…¨å±€é‡è¦æ€§å›¾ã€‚")
                    # st.error(str(e)) # è°ƒè¯•ç”¨
            else:
                st.warning("æ— æ³•åŠ è½½è®­ç»ƒæ•°æ®ï¼Œæ— æ³•è¿›è¡Œå®æ—¶ SHAP åˆ†æã€‚")

        with tab2:
            st.subheader("å…¨å±€ç‰¹å¾é‡è¦æ€§")
            st.markdown("è¯¥å›¾å±•ç¤ºäº†æ¨¡å‹åœ¨æ•´ä½“è®­ç»ƒæ•°æ®ä¸Šè®¤ä¸ºæœ€é‡è¦çš„é£é™©å› å­ã€‚")
            
            # å°è¯•åŠ è½½é¢„ç”Ÿæˆçš„å›¾ç‰‡
            summary_plot_path = os.path.join(plot_dir, "SHAP_Analysis", "Training_Set", f"{selected_model_name}_shap_summary.png")
            importance_plot_path = os.path.join(plot_dir, "SHAP_Analysis", "Training_Set", f"{selected_model_name}_shap_importance.png")
            
            if os.path.exists(summary_plot_path):
                st.image(summary_plot_path, caption=f"{selected_model_name} SHAP Summary Plot", use_container_width=True)
            elif os.path.exists(importance_plot_path):
                st.image(importance_plot_path, caption=f"{selected_model_name} Feature Importance", use_container_width=True)
            else:
                st.info("æš‚æ— è¯¥æ¨¡å‹çš„å…¨å±€é‡è¦æ€§å›¾è¡¨ã€‚")

        with tab3:
            st.subheader("æ¨¡å‹æ€§èƒ½è¯„ä¼°")
            c_roc, c_recall = st.columns(2)
            
            with c_roc:
                st.markdown("**ROC æ›²çº¿**")
                
                roc_path = os.path.join(roc_dir, f"roc_curve_{selected_model_name}_test.png")
                
                # å¦‚æœæ²¡æœ‰testï¼Œå°è¯•æ‰¾trainæˆ–è€…é€šç”¨çš„
                if not os.path.exists(roc_path):
                     roc_path = os.path.join(roc_dir, f"roc_curve_{selected_model_name}.png")
                
                if os.path.exists(roc_path):
                    st.image(roc_path, caption=f"{selected_model_name} ROC Curve", use_container_width=True)
                else:
                    st.info(f"æš‚æ—  ROC æ›²çº¿å›¾ã€‚ (æœªæ‰¾åˆ°: {roc_path})")
            
            with c_recall:
                st.markdown("**Precision-Recall æ›²çº¿**")
                pr_path = os.path.join(plot_dir, "Recall_Curves", f"recall_curve_{selected_model_name}_test.png")
                if os.path.exists(pr_path):
                    st.image(pr_path, caption=f"{selected_model_name} Recall Curve", use_container_width=True)
                else:
                    st.info("æš‚æ—  Recall æ›²çº¿å›¾ã€‚")

        with tab4:
            st.subheader("è®­ç»ƒæ•°æ®æ‘˜è¦")
            if X_train is not None:
                display_train = X_train.copy()
                display_train.columns = [
                    'AGE [å²]', 'BMI [kg/mÂ²]', 'FBG [mg/dL]', 
                    'HBA1C [%]', 'HDL [mg/dL]', 'TG [mg/dL]', 'UA [mg/dL]'
                ]
                st.write(display_train.describe())
            else:
                st.warning("è®­ç»ƒæ•°æ®åŠ è½½å¤±è´¥ã€‚")

    except Exception as e:
        st.error(f"é¢„æµ‹è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        st.write("è¯¦ç»†é”™è¯¯ä¿¡æ¯:", str(e))

# é¡µè„š
st.markdown("---")
st.caption("æ³¨ï¼šæœ¬å·¥å…·ä»…ä¾›ä¸´åºŠè¾…åŠ©å‚è€ƒï¼Œä¸èƒ½æ›¿ä»£åŒ»ç”Ÿè¯Šæ–­ã€‚ | Developed with Streamlit")